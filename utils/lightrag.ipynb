{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54827f5-0bd6-4d4c-93d4-1e47ecccfc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: ./dickens\n",
      "INFO:lightrag:Load KV llm_response_cache with 0 data\n",
      "INFO:lightrag:Load KV full_docs with 0 data\n",
      "INFO:lightrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './dickens/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './dickens/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': './dickens/vdb_chunks.json'} 0 data\n",
      "INFO:lightrag:Loaded document status storage with 0 records\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     16\u001b[0m rag \u001b[38;5;241m=\u001b[39m LightRAG(\n\u001b[1;32m     17\u001b[0m     working_dir\u001b[38;5;241m=\u001b[39mWORKING_DIR,\n\u001b[1;32m     18\u001b[0m     llm_model_func\u001b[38;5;241m=\u001b[39mollama_model_complete,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     ),\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./book.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mrag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Perform naive search\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     37\u001b[0m     rag\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the top themes in this story?\u001b[39m\u001b[38;5;124m\"\u001b[39m, param\u001b[38;5;241m=\u001b[39mQueryParam(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnaive\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/scrape/lib/python3.12/site-packages/lightrag/lightrag.py:325\u001b[0m, in \u001b[0;36mLightRAG.insert\u001b[0;34m(self, string_or_strings, split_by_character, split_by_character_only)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsert\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m, string_or_strings, split_by_character\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, split_by_character_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    323\u001b[0m ):\n\u001b[1;32m    324\u001b[0m     loop \u001b[38;5;241m=\u001b[39m always_get_an_event_loop()\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mainsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring_or_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_by_character\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_by_character_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/scrape/lib/python3.12/asyncio/base_events.py:663\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m--> 663\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m new_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m futures\u001b[38;5;241m.\u001b[39misfuture(future)\n\u001b[1;32m    666\u001b[0m future \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mensure_future(future, loop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/scrape/lib/python3.12/asyncio/base_events.py:622\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_running\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m--> 622\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis event loop is already running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    625\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot run the event loop while another loop is running\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import inspect\n",
    "import logging\n",
    "from lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm import ollama_model_complete, ollama_embedding\n",
    "from lightrag.utils import EmbeddingFunc\n",
    "\n",
    "WORKING_DIR = \"./dickens\"\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s:%(message)s\", level=logging.INFO)\n",
    "\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)\n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=ollama_model_complete,\n",
    "    llm_model_name=\"llama3.2\",\n",
    "    llm_model_max_async=4,\n",
    "    llm_model_max_token_size=32768,\n",
    "    llm_model_kwargs={\"host\": \"http://localhost:11434\", \"options\": {\"num_ctx\": 32768}},\n",
    "    embedding_func=EmbeddingFunc(\n",
    "        embedding_dim=768,\n",
    "        max_token_size=8192,\n",
    "        func=lambda texts: ollama_embedding(\n",
    "            texts, embed_model=\"nomic-embed-text\", host=\"http://localhost:11434\"\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "with open(\"./book.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    rag.insert(f.read())\n",
    "\n",
    "# Perform naive search\n",
    "print(\n",
    "    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\"))\n",
    ")\n",
    "\n",
    "# Perform local search\n",
    "print(\n",
    "    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\"))\n",
    ")\n",
    "\n",
    "# Perform global search\n",
    "print(\n",
    "    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\"))\n",
    ")\n",
    "\n",
    "# Perform hybrid search\n",
    "print(\n",
    "    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\"))\n",
    ")\n",
    "\n",
    "# stream response\n",
    "resp = rag.query(\n",
    "    \"What are the top themes in this story?\",\n",
    "    param=QueryParam(mode=\"hybrid\", stream=True),\n",
    ")\n",
    "\n",
    "\n",
    "async def print_stream(stream):\n",
    "    async for chunk in stream:\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "if inspect.isasyncgen(resp):\n",
    "    asyncio.run(print_stream(resp))\n",
    "else:\n",
    "    print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff2c5c4-45ec-4807-a920-a5ca7e3a6f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surface concentration of hydroxyls: 2.1 1/nm^2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "n = 36\n",
    "d = 1.4\n",
    "l = 3.8154\n",
    "surface = d * math.pi * l\n",
    "conc = n/surface\n",
    "print(f'Surface concentration of hydroxyls: {round(conc, 1)} 1/nm^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c21d81c4-99db-4261-b315-ef4c644063a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.9 OH/nm^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421ec8e-bfd9-4107-b3a5-ff6d5d14afc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
